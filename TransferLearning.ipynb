{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBYr2UDVafQT","executionInfo":{"status":"ok","timestamp":1747711413381,"user_tz":420,"elapsed":20787,"user":{"displayName":"Saeah Go","userId":"04837396225806613326"}},"outputId":"c990c185-3fb1-4c92-87dd-34ac2bc5a427"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Evaluating on custom_foggy_25.npy: 100%|██████████| 395/395 [00:19<00:00, 20.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics for custom_foggy_25.npy\n","Accuracy : 97.69%\n","Precision: 97.76%\n","Recall   : 97.69%\n","F1 Score : 97.69%\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.95      1.00      0.98        60\n","           1       0.99      0.99      0.99       720\n","           2       1.00      0.99      0.99       750\n","           3       0.98      0.93      0.96       450\n","           4       0.99      0.99      0.99       660\n","           5       0.94      0.99      0.97       630\n","           6       0.99      0.95      0.97       150\n","           7       0.98      0.95      0.97       450\n","           8       0.99      0.96      0.98       450\n","           9       0.98      1.00      0.99       480\n","          10       0.99      0.99      0.99       660\n","          11       0.96      0.97      0.96       420\n","          12       1.00      1.00      1.00       690\n","          13       1.00      1.00      1.00       720\n","          14       0.99      0.99      0.99       270\n","          15       0.91      1.00      0.95       210\n","          16       1.00      0.93      0.96       150\n","          17       1.00      0.98      0.99       360\n","          18       0.97      0.99      0.98       390\n","          19       0.97      0.93      0.95        60\n","          20       0.93      0.99      0.96        90\n","          21       0.99      0.96      0.97        90\n","          22       0.98      0.89      0.93       120\n","          23       0.99      0.94      0.97       150\n","          24       0.98      0.98      0.98        90\n","          25       0.97      0.99      0.98       480\n","          26       0.94      0.93      0.94       180\n","          27       0.95      0.95      0.95        60\n","          28       1.00      0.98      0.99       150\n","          29       0.83      1.00      0.90        90\n","          30       0.98      0.88      0.93       150\n","          31       0.95      0.95      0.95       270\n","          32       1.00      1.00      1.00        60\n","          33       0.98      1.00      0.99       210\n","          34       0.99      1.00      1.00       120\n","          35       0.96      0.96      0.96       390\n","          36       0.94      0.98      0.96       120\n","          37       0.92      0.78      0.85        60\n","          38       0.98      1.00      0.99       690\n","          39       1.00      0.91      0.95        90\n","          40       0.81      0.93      0.87        90\n","          41       1.00      1.00      1.00        60\n","          42       0.96      0.94      0.95        90\n","\n","    accuracy                           0.98     12630\n","   macro avg       0.97      0.96      0.97     12630\n","weighted avg       0.98      0.98      0.98     12630\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# --- CONFIG ---\n","# Base working directory\n","base_dir = \"/content/drive/Shared drives/VisualCompGroupProject\"\n","\n","# Dataset path: just change this to test a different weather effect!\n","dataset_name = \"custom_foggy_25.npy\"  # Change to: custom_rainy.npy, custom_snowy.npy\n","dataset_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", dataset_name)\n","\n","# Path to model\n","model_path = os.path.join(base_dir, \"resnet50_model.pth\")\n","\n","# Path to labels (must be aligned with test data)\n","y_test_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", \"labels_foggy_25.npy\")  # Assumes labels are the same\n","\n","# --- Dataset Wrapper ---\n","class NumpyDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = Image.fromarray(self.images[idx])\n","        if self.transform:\n","            img = self.transform(img)\n","        label = int(self.labels[idx])\n","        return img, label\n","\n","# --- Preprocessing ---\n","# These values are standard for ImageNet (which ResNet50 expects)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std =[0.229, 0.224, 0.225])\n","])\n","\n","# --- Load Data ---\n","X_test = np.load(dataset_path)\n","y_test = np.load(y_test_path)\n","\n","# Ensure dtype is correct\n","X_test = X_test.astype(np.uint8)\n","\n","# Create DataLoader\n","test_dataset = NumpyDataset(X_test, y_test, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# --- Load Model ---\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained ResNet50 and match output classes\n","model = models.resnet50(pretrained=False)\n","num_classes = len(np.unique(y_test))\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","# --- Evaluation ---\n","all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=f\"Evaluating on {dataset_name}\"):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        all_preds.extend(predicted.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# --- Metrics ---\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n","recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n","f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n","\n","print(f\"\\nEvaluation Metrics for {dataset_name}\")\n","print(f\"Accuracy : {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall   : {recall * 100:.2f}%\")\n","print(f\"F1 Score : {f1 * 100:.2f}%\")\n","\n","# Optional: print full classification report\n","print(\"\\nDetailed Classification Report:\")\n","print(classification_report(all_labels, all_preds, zero_division=0))"]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# --- CONFIG ---\n","# Base working directory\n","base_dir = \"/content/drive/Shared drives/VisualCompGroupProject\"\n","\n","# Dataset path: just change this to test a different weather effect!\n","dataset_name = \"custom_foggy_50.npy\"  # Change to: custom_rainy.npy, custom_snowy.npy\n","dataset_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", dataset_name)\n","\n","# Path to model\n","model_path = os.path.join(base_dir, \"resnet50_model.pth\")\n","\n","# Path to labels (must be aligned with test data)\n","y_test_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", \"labels_foggy_50.npy\")  # Assumes labels are the same\n","\n","# --- Dataset Wrapper ---\n","class NumpyDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = Image.fromarray(self.images[idx])\n","        if self.transform:\n","            img = self.transform(img)\n","        label = int(self.labels[idx])\n","        return img, label\n","\n","# --- Preprocessing ---\n","# These values are standard for ImageNet (which ResNet50 expects)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std =[0.229, 0.224, 0.225])\n","])\n","\n","# --- Load Data ---\n","X_test = np.load(dataset_path)\n","y_test = np.load(y_test_path)\n","\n","# Ensure dtype is correct\n","X_test = X_test.astype(np.uint8)\n","\n","# Create DataLoader\n","test_dataset = NumpyDataset(X_test, y_test, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# --- Load Model ---\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained ResNet50 and match output classes\n","model = models.resnet50(pretrained=False)\n","num_classes = len(np.unique(y_test))\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# --- Evaluation ---\n","all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=f\"Evaluating on {dataset_name}\"):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        all_preds.extend(predicted.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# --- Metrics ---\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n","recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n","f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n","\n","print(f\"\\nEvaluation Metrics for {dataset_name}\")\n","print(f\"Accuracy : {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall   : {recall * 100:.2f}%\")\n","print(f\"F1 Score : {f1 * 100:.2f}%\")\n","\n","# Optional: print full classification report\n","print(\"\\nDetailed Classification Report:\")\n","print(classification_report(all_labels, all_preds, zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7fFXRlXsIuO","executionInfo":{"status":"ok","timestamp":1747711481287,"user_tz":420,"elapsed":25629,"user":{"displayName":"Saeah Go","userId":"04837396225806613326"}},"outputId":"c72d2d79-af28-4cb4-cff7-c81c34cf6aff"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Evaluating on custom_foggy_50.npy: 100%|██████████| 395/395 [00:23<00:00, 16.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics for custom_foggy_50.npy\n","Accuracy : 96.42%\n","Precision: 96.61%\n","Recall   : 96.42%\n","F1 Score : 96.42%\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.95      1.00      0.98        60\n","           1       0.99      0.99      0.99       720\n","           2       0.99      0.98      0.99       750\n","           3       0.95      0.92      0.94       450\n","           4       0.99      0.98      0.98       660\n","           5       0.93      0.99      0.96       630\n","           6       0.99      0.89      0.94       150\n","           7       0.98      0.93      0.96       450\n","           8       1.00      0.92      0.96       450\n","           9       0.97      0.99      0.98       480\n","          10       0.98      0.98      0.98       660\n","          11       0.94      0.94      0.94       420\n","          12       1.00      0.99      1.00       690\n","          13       1.00      1.00      1.00       720\n","          14       0.97      0.99      0.98       270\n","          15       0.84      1.00      0.91       210\n","          16       1.00      0.89      0.94       150\n","          17       1.00      0.97      0.98       360\n","          18       0.95      0.98      0.96       390\n","          19       1.00      0.92      0.96        60\n","          20       0.94      1.00      0.97        90\n","          21       0.99      0.94      0.97        90\n","          22       0.96      0.89      0.93       120\n","          23       0.99      0.89      0.94       150\n","          24       0.92      0.98      0.95        90\n","          25       0.97      0.98      0.97       480\n","          26       0.92      0.91      0.91       180\n","          27       0.87      0.88      0.88        60\n","          28       0.99      0.95      0.97       150\n","          29       0.78      1.00      0.88        90\n","          30       0.96      0.79      0.87       150\n","          31       0.92      0.94      0.93       270\n","          32       1.00      1.00      1.00        60\n","          33       1.00      1.00      1.00       210\n","          34       1.00      1.00      1.00       120\n","          35       0.93      0.96      0.94       390\n","          36       0.90      0.98      0.94       120\n","          37       0.90      0.60      0.72        60\n","          38       0.96      1.00      0.98       690\n","          39       1.00      0.82      0.90        90\n","          40       0.70      0.96      0.81        90\n","          41       0.98      1.00      0.99        60\n","          42       0.93      0.86      0.89        90\n","\n","    accuracy                           0.96     12630\n","   macro avg       0.95      0.94      0.95     12630\n","weighted avg       0.97      0.96      0.96     12630\n","\n"]}]},{"cell_type":"markdown","source":["# Snow"],"metadata":{"id":"WEhD4GvUsOVx"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# --- CONFIG ---\n","# Base working directory\n","base_dir = \"/content/drive/Shared drives/VisualCompGroupProject\"\n","\n","# Dataset path: just change this to test a different weather effect!\n","dataset_name = \"custom_snowy_25.npy\"  # Change to: custom_rainy.npy, custom_snowy.npy\n","dataset_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", dataset_name)\n","\n","# Path to model\n","model_path = os.path.join(base_dir, \"resnet50_model.pth\")\n","\n","# Path to labels (must be aligned with test data)\n","y_test_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", \"labels_snowy_25.npy\")  # Assumes labels are the same\n","\n","# --- Dataset Wrapper ---\n","class NumpyDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = Image.fromarray(self.images[idx])\n","        if self.transform:\n","            img = self.transform(img)\n","        label = int(self.labels[idx])\n","        return img, label\n","\n","# --- Preprocessing ---\n","# These values are standard for ImageNet (which ResNet50 expects)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std =[0.229, 0.224, 0.225])\n","])\n","\n","# --- Load Data ---\n","X_test = np.load(dataset_path)\n","y_test = np.load(y_test_path)\n","\n","# Ensure dtype is correct\n","X_test = X_test.astype(np.uint8)\n","\n","# Create DataLoader\n","test_dataset = NumpyDataset(X_test, y_test, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# --- Load Model ---\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained ResNet50 and match output classes\n","model = models.resnet50(pretrained=False)\n","num_classes = len(np.unique(y_test))\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# --- Evaluation ---\n","all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=f\"Evaluating on {dataset_name}\"):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        all_preds.extend(predicted.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# --- Metrics ---\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n","recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n","f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n","\n","print(f\"\\nEvaluation Metrics for {dataset_name}\")\n","print(f\"Accuracy : {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall   : {recall * 100:.2f}%\")\n","print(f\"F1 Score : {f1 * 100:.2f}%\")\n","\n","# Optional: print full classification report\n","print(\"\\nDetailed Classification Report:\")\n","print(classification_report(all_labels, all_preds, zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZKhH05tsNz8","executionInfo":{"status":"ok","timestamp":1747711540585,"user_tz":420,"elapsed":20927,"user":{"displayName":"Saeah Go","userId":"04837396225806613326"}},"outputId":"147fee08-0713-4f3e-9610-fafd4ca8424d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Evaluating on custom_snowy_25.npy: 100%|██████████| 395/395 [00:19<00:00, 20.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics for custom_snowy_25.npy\n","Accuracy : 81.86%\n","Precision: 91.78%\n","Recall   : 81.86%\n","F1 Score : 85.02%\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.82      0.88        60\n","           1       0.97      0.88      0.92       720\n","           2       0.91      0.86      0.89       750\n","           3       1.00      0.73      0.84       450\n","           4       0.99      0.77      0.86       660\n","           5       0.97      0.78      0.86       630\n","           6       0.95      0.70      0.80       150\n","           7       0.98      0.74      0.84       450\n","           8       0.99      0.74      0.84       450\n","           9       0.99      0.77      0.87       480\n","          10       0.98      0.75      0.85       660\n","          11       0.82      0.92      0.87       420\n","          12       1.00      0.87      0.93       690\n","          13       0.96      0.94      0.95       720\n","          14       0.67      0.90      0.77       270\n","          15       0.99      0.86      0.92       210\n","          16       1.00      0.77      0.87       150\n","          17       1.00      0.86      0.92       360\n","          18       0.99      0.79      0.88       390\n","          19       0.85      0.93      0.89        60\n","          20       0.21      0.78      0.33        90\n","          21       0.94      0.89      0.91        90\n","          22       1.00      0.65      0.79       120\n","          23       0.80      0.84      0.82       150\n","          24       0.96      0.77      0.85        90\n","          25       0.33      0.91      0.48       480\n","          26       0.98      0.83      0.90       180\n","          27       0.89      0.83      0.86        60\n","          28       0.92      0.79      0.85       150\n","          29       0.63      0.87      0.73        90\n","          30       0.93      0.77      0.84       150\n","          31       0.98      0.79      0.87       270\n","          32       1.00      0.85      0.92        60\n","          33       0.99      0.81      0.89       210\n","          34       0.98      0.91      0.94       120\n","          35       0.99      0.79      0.88       390\n","          36       0.98      0.68      0.80       120\n","          37       0.29      0.90      0.44        60\n","          38       0.96      0.79      0.87       690\n","          39       1.00      0.78      0.88        90\n","          40       0.15      0.91      0.26        90\n","          41       0.86      0.90      0.88        60\n","          42       0.95      0.77      0.85        90\n","\n","    accuracy                           0.82     12630\n","   macro avg       0.88      0.82      0.82     12630\n","weighted avg       0.92      0.82      0.85     12630\n","\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# --- CONFIG ---\n","# Base working directory\n","base_dir = \"/content/drive/Shared drives/VisualCompGroupProject\"\n","\n","# Dataset path: just change this to test a different weather effect!\n","dataset_name = \"custom_snowy_50.npy\"  # Change to: custom_rainy.npy, custom_snowy.npy\n","dataset_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", dataset_name)\n","\n","# Path to model\n","model_path = os.path.join(base_dir, \"resnet50_model.pth\")\n","\n","# Path to labels (must be aligned with test data)\n","y_test_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", \"labels_snowy_50.npy\")  # Assumes labels are the same\n","\n","# --- Dataset Wrapper ---\n","class NumpyDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = Image.fromarray(self.images[idx])\n","        if self.transform:\n","            img = self.transform(img)\n","        label = int(self.labels[idx])\n","        return img, label\n","\n","# --- Preprocessing ---\n","# These values are standard for ImageNet (which ResNet50 expects)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std =[0.229, 0.224, 0.225])\n","])\n","\n","# --- Load Data ---\n","X_test = np.load(dataset_path)\n","y_test = np.load(y_test_path)\n","\n","# Ensure dtype is correct\n","X_test = X_test.astype(np.uint8)\n","\n","# Create DataLoader\n","test_dataset = NumpyDataset(X_test, y_test, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# --- Load Model ---\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained ResNet50 and match output classes\n","model = models.resnet50(pretrained=False)\n","num_classes = len(np.unique(y_test))\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# --- Evaluation ---\n","all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=f\"Evaluating on {dataset_name}\"):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        all_preds.extend(predicted.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# --- Metrics ---\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n","recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n","f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n","\n","print(f\"\\nEvaluation Metrics for {dataset_name}\")\n","print(f\"Accuracy : {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall   : {recall * 100:.2f}%\")\n","print(f\"F1 Score : {f1 * 100:.2f}%\")\n","\n","# Optional: print full classification report\n","print(\"\\nDetailed Classification Report:\")\n","print(classification_report(all_labels, all_preds, zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjtbrwxwsVXZ","executionInfo":{"status":"ok","timestamp":1747711564730,"user_tz":420,"elapsed":20915,"user":{"displayName":"Saeah Go","userId":"04837396225806613326"}},"outputId":"815d7d71-4f57-4482-815a-a9c788cd1ab5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Evaluating on custom_snowy_50.npy: 100%|██████████| 395/395 [00:19<00:00, 20.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics for custom_snowy_50.npy\n","Accuracy : 63.75%\n","Precision: 86.85%\n","Recall   : 63.75%\n","F1 Score : 70.25%\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.55      0.66        60\n","           1       0.94      0.71      0.81       720\n","           2       0.82      0.67      0.73       750\n","           3       1.00      0.49      0.66       450\n","           4       0.96      0.53      0.69       660\n","           5       0.93      0.53      0.68       630\n","           6       0.87      0.49      0.62       150\n","           7       0.95      0.51      0.66       450\n","           8       0.95      0.47      0.63       450\n","           9       0.97      0.60      0.74       480\n","          10       0.98      0.50      0.66       660\n","          11       0.66      0.80      0.72       420\n","          12       1.00      0.74      0.85       690\n","          13       0.93      0.86      0.89       720\n","          14       0.48      0.83      0.61       270\n","          15       0.98      0.72      0.83       210\n","          16       1.00      0.59      0.74       150\n","          17       1.00      0.71      0.83       360\n","          18       0.98      0.57      0.72       390\n","          19       0.65      0.58      0.61        60\n","          20       0.08      0.52      0.14        90\n","          21       0.90      0.87      0.88        90\n","          22       1.00      0.47      0.64       120\n","          23       0.60      0.65      0.62       150\n","          24       0.80      0.46      0.58        90\n","          25       0.19      0.86      0.31       480\n","          26       0.96      0.70      0.81       180\n","          27       0.74      0.57      0.64        60\n","          28       0.82      0.72      0.77       150\n","          29       0.37      0.70      0.48        90\n","          30       0.81      0.61      0.69       150\n","          31       0.99      0.52      0.68       270\n","          32       0.96      0.40      0.56        60\n","          33       1.00      0.59      0.74       210\n","          34       0.99      0.73      0.84       120\n","          35       0.99      0.65      0.78       390\n","          36       0.98      0.40      0.57       120\n","          37       0.15      0.82      0.26        60\n","          38       0.91      0.61      0.73       690\n","          39       1.00      0.67      0.80        90\n","          40       0.07      0.81      0.13        90\n","          41       0.61      0.73      0.67        60\n","          42       0.93      0.41      0.57        90\n","\n","    accuracy                           0.64     12630\n","   macro avg       0.81      0.63      0.66     12630\n","weighted avg       0.87      0.64      0.70     12630\n","\n"]}]},{"cell_type":"markdown","source":["# Rain"],"metadata":{"id":"fJGeKzdHsb_S"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# --- CONFIG ---\n","# Base working directory\n","base_dir = \"/content/drive/Shared drives/VisualCompGroupProject\"\n","\n","# Dataset path: just change this to test a different weather effect!\n","dataset_name = \"custom_rainy_25.npy\"  # Change to: custom_rainy.npy, custom_snowy.npy\n","dataset_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", dataset_name)\n","\n","# Path to model\n","model_path = os.path.join(base_dir, \"resnet50_model.pth\")\n","\n","# Path to labels (must be aligned with test data)\n","y_test_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", \"labels_rainy_25.npy\")  # Assumes labels are the same\n","\n","# --- Dataset Wrapper ---\n","class NumpyDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = Image.fromarray(self.images[idx])\n","        if self.transform:\n","            img = self.transform(img)\n","        label = int(self.labels[idx])\n","        return img, label\n","\n","# --- Preprocessing ---\n","# These values are standard for ImageNet (which ResNet50 expects)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std =[0.229, 0.224, 0.225])\n","])\n","\n","# --- Load Data ---\n","X_test = np.load(dataset_path)\n","y_test = np.load(y_test_path)\n","\n","# Ensure dtype is correct\n","X_test = X_test.astype(np.uint8)\n","\n","# Create DataLoader\n","test_dataset = NumpyDataset(X_test, y_test, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# --- Load Model ---\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained ResNet50 and match output classes\n","model = models.resnet50(pretrained=False)\n","num_classes = len(np.unique(y_test))\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# --- Evaluation ---\n","all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=f\"Evaluating on {dataset_name}\"):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        all_preds.extend(predicted.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# --- Metrics ---\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n","recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n","f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n","\n","print(f\"\\nEvaluation Metrics for {dataset_name}\")\n","print(f\"Accuracy : {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall   : {recall * 100:.2f}%\")\n","print(f\"F1 Score : {f1 * 100:.2f}%\")\n","\n","# Optional: print full classification report\n","print(\"\\nDetailed Classification Report:\")\n","print(classification_report(all_labels, all_preds, zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNMx00bosc_G","executionInfo":{"status":"ok","timestamp":1747711592315,"user_tz":420,"elapsed":20834,"user":{"displayName":"Saeah Go","userId":"04837396225806613326"}},"outputId":"4f4cdf2e-8090-4429-cae7-2551a25bd2c8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Evaluating on custom_rainy_25.npy: 100%|██████████| 395/395 [00:19<00:00, 20.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics for custom_rainy_25.npy\n","Accuracy : 83.10%\n","Precision: 90.12%\n","Recall   : 83.10%\n","F1 Score : 85.06%\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.78      0.82        60\n","           1       0.90      0.90      0.90       720\n","           2       0.90      0.85      0.88       750\n","           3       1.00      0.70      0.83       450\n","           4       0.97      0.80      0.88       660\n","           5       0.97      0.79      0.87       630\n","           6       0.97      0.75      0.85       150\n","           7       0.97      0.75      0.84       450\n","           8       1.00      0.78      0.87       450\n","           9       0.99      0.82      0.89       480\n","          10       0.99      0.77      0.87       660\n","          11       0.78      0.92      0.84       420\n","          12       1.00      0.91      0.95       690\n","          13       0.73      0.96      0.83       720\n","          14       0.71      0.94      0.81       270\n","          15       1.00      0.81      0.89       210\n","          16       1.00      0.82      0.90       150\n","          17       1.00      0.88      0.93       360\n","          18       0.97      0.83      0.89       390\n","          19       0.79      0.83      0.81        60\n","          20       0.25      0.79      0.38        90\n","          21       0.82      0.91      0.86        90\n","          22       0.99      0.71      0.83       120\n","          23       0.93      0.87      0.90       150\n","          24       0.63      0.77      0.69        90\n","          25       0.45      0.95      0.61       480\n","          26       0.98      0.83      0.90       180\n","          27       0.87      0.75      0.80        60\n","          28       0.84      0.81      0.82       150\n","          29       0.95      0.81      0.87        90\n","          30       0.97      0.74      0.84       150\n","          31       0.98      0.73      0.84       270\n","          32       0.98      0.78      0.87        60\n","          33       0.96      0.74      0.83       210\n","          34       0.99      0.82      0.90       120\n","          35       0.98      0.78      0.87       390\n","          36       0.93      0.77      0.84       120\n","          37       0.21      0.98      0.35        60\n","          38       0.99      0.80      0.89       690\n","          39       0.85      0.91      0.88        90\n","          40       0.23      0.90      0.37        90\n","          41       0.75      0.82      0.78        60\n","          42       0.87      0.73      0.80        90\n","\n","    accuracy                           0.83     12630\n","   macro avg       0.86      0.82      0.82     12630\n","weighted avg       0.90      0.83      0.85     12630\n","\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# --- CONFIG ---\n","# Base working directory\n","base_dir = \"/content/drive/Shared drives/VisualCompGroupProject\"\n","\n","# Dataset path: just change this to test a different weather effect!\n","dataset_name = \"custom_rainy_50.npy\"  # Change to: custom_rainy.npy, custom_snowy.npy\n","dataset_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", dataset_name)\n","\n","# Path to model\n","model_path = os.path.join(base_dir, \"resnet50_model.pth\")\n","\n","# Path to labels (must be aligned with test data)\n","y_test_path = os.path.join(base_dir, \"SimpleMethodAugmentation\", \"labels_rainy_50.npy\")  # Assumes labels are the same\n","\n","# --- Dataset Wrapper ---\n","class NumpyDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = Image.fromarray(self.images[idx])\n","        if self.transform:\n","            img = self.transform(img)\n","        label = int(self.labels[idx])\n","        return img, label\n","\n","# --- Preprocessing ---\n","# These values are standard for ImageNet (which ResNet50 expects)\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std =[0.229, 0.224, 0.225])\n","])\n","\n","# --- Load Data ---\n","X_test = np.load(dataset_path)\n","y_test = np.load(y_test_path)\n","\n","# Ensure dtype is correct\n","X_test = X_test.astype(np.uint8)\n","\n","# Create DataLoader\n","test_dataset = NumpyDataset(X_test, y_test, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# --- Load Model ---\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained ResNet50 and match output classes\n","model = models.resnet50(pretrained=False)\n","num_classes = len(np.unique(y_test))\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# --- Evaluation ---\n","all_preds = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=f\"Evaluating on {dataset_name}\"):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        all_preds.extend(predicted.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# --- Metrics ---\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n","recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n","f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n","\n","print(f\"\\nEvaluation Metrics for {dataset_name}\")\n","print(f\"Accuracy : {accuracy * 100:.2f}%\")\n","print(f\"Precision: {precision * 100:.2f}%\")\n","print(f\"Recall   : {recall * 100:.2f}%\")\n","print(f\"F1 Score : {f1 * 100:.2f}%\")\n","\n","# Optional: print full classification report\n","print(\"\\nDetailed Classification Report:\")\n","print(classification_report(all_labels, all_preds, zero_division=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4RBTwMDsgli","executionInfo":{"status":"ok","timestamp":1747711143691,"user_tz":420,"elapsed":26656,"user":{"displayName":"Saeah Go","userId":"04837396225806613326"}},"outputId":"75c321b3-1d3f-4cd8-e345-0603274cc5ed"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating on custom_rainy_50.npy: 100%|██████████| 395/395 [00:19<00:00, 20.59it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy on custom_rainy_50.npy: 65.95%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}